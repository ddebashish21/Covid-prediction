{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOsjYw0TcySLa+ShZiG/rtd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ddebashish21/Covid-prediction/blob/main/Covid_Prediction_using_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Image Classification for the prediction of Covid-19 using lung's X-ray**"
      ],
      "metadata": {
        "id": "1aZWIxRijZ6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains images of the lung's X-ray of normal people and the lung's X-ray of Covid-19 patients. The aim of the project is to train a model to distinguise the covid-19 patients from the normal patients using the X-ray images."
      ],
      "metadata": {
        "id": "_2WJ_jGfYKzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing all the essential libraries\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "import cv2"
      ],
      "metadata": {
        "id": "6dg96nBQf-9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the directories for storing image datas\n",
        "mkdir covid_dataset"
      ],
      "metadata": {
        "id": "O6pWOIZ8oHNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir covid_dataset/train"
      ],
      "metadata": {
        "id": "nKW6vRcRkds3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir covid_dataset/test"
      ],
      "metadata": {
        "id": "7k7c0IF6H7kY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir covid_dataset/train/covid"
      ],
      "metadata": {
        "id": "0DNft0peIB0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir covid_dataset/train/normal"
      ],
      "metadata": {
        "id": "0tapAXIsIUtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir covid_dataset/test/covid"
      ],
      "metadata": {
        "id": "wrZB0zQpIX1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir covid_dataset/test/normal"
      ],
      "metadata": {
        "id": "L8QxQzWSId3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing the address of training and testing datas\n",
        "ref={\"train\": \"/content/covid_dataset/train\",\n",
        "     \"test\": \"/content/covid_dataset/test\"}"
      ],
      "metadata": {
        "id": "e2W9grftJ3i9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing the image dataset for training**"
      ],
      "metadata": {
        "id": "W6czWyFiNoAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing the training data\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)"
      ],
      "metadata": {
        "id": "qHO9WCKcM_-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing the testing data\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "Gz--Qc11Ni49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = train_datagen.flow_from_directory(ref[\"train\"],\n",
        "                                                 target_size=(64, 64),\n",
        "                                                 batch_size=32,\n",
        "                                                 class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7ubvv6mNxkk",
        "outputId": "84f6c997-7997-4b79-cacf-7cfd1c35777f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 181 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing_data = test_datagen.flow_from_directory(ref[\"test\"],\n",
        "                                               target_size=(64, 64),\n",
        "                                               batch_size=32,\n",
        "                                               class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_2EjEmPOIgn",
        "outputId": "4223833f-9d4e-4f13-8e9d-4509887bf538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 46 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_data.class_indices)\n",
        "print(testing_data.class_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CKXNj92OVlj",
        "outputId": "c29f71b4-a9e3-4a7c-e00d-ef6878937a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'covid': 0, 'normal': 1}\n",
            "{'covid': 0, 'normal': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ombJMT63edOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(64,64,3))) # 1st Convolution layer\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) # 1st Pooling layer using the maximum value\n",
        "model.add(Conv2D(16,(3,3),activation='relu')) # 2nd Convokution layer\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) # 2nd Pooling layer using the maximum value\n",
        "model.add(Flatten()) # Fully-connected layer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYN7nPSwTmrH",
        "outputId": "f74bd15b-cea3-4009-dfd1-8923380e57a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding 3 hidden layers of Neural network\n",
        "model.add(Dense(units=128,activation='relu'))\n",
        "model.add(Dense(units=64,activation='relu'))\n",
        "model.add(Dense(units=1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "Rze9J-jlUvbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model using accuracy metrics\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ylOAXLd9U6yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model using the training dataset and validating it using testing dataset\n",
        "model.fit(training_data,\n",
        "          steps_per_epoch=int(len(training_data)/32),\n",
        "          epochs=5,\n",
        "          validation_data=testing_data,\n",
        "          validation_steps=int(len(testing_data)/32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8ASXRcmU_v3",
        "outputId": "afdbbde6-a9b8-411f-acb3-708ff60cb778"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 324ms/step - accuracy: 0.9177 - loss: 0.2009 - val_accuracy: 0.9565 - val_loss: 0.1418\n",
            "Epoch 2/5\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 206ms/step - accuracy: 0.9335 - loss: 0.1570 - val_accuracy: 0.9565 - val_loss: 0.1479\n",
            "Epoch 3/5\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 215ms/step - accuracy: 0.8973 - loss: 0.1844 - val_accuracy: 0.9565 - val_loss: 0.1375\n",
            "Epoch 4/5\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 361ms/step - accuracy: 0.9140 - loss: 0.2003 - val_accuracy: 0.9565 - val_loss: 0.1372\n",
            "Epoch 5/5\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 208ms/step - accuracy: 0.9032 - loss: 0.1617 - val_accuracy: 0.9348 - val_loss: 0.1685\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7bf5c24db1f0>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing the models accuracy using images manually**"
      ],
      "metadata": {
        "id": "s-AnRHKQhZlq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the necessary libraries\n",
        "import keras.preprocessing.image as image\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "thbkZeFu4-Pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting the dimension of the image according to the model requirements\n",
        "img1=image.load_img('/content/covid_dataset/test/covid/COVID-00003b.jpg',target_size=(64,64))\n",
        "img2=image.load_img('/content/covid_dataset/test/normal/0105.jpeg',target_size=(64,64))"
      ],
      "metadata": {
        "id": "270p5Sm1h1MC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing the pixels and expanding the size of the image\n",
        "test_img1=image.img_to_array(img1)\n",
        "test_img2=image.img_to_array(img2)\n",
        "test_img1=test_img1/255.\n",
        "test_img2=test_img2/255.\n",
        "test_img1=np.expand_dims(test_img1,axis=0)\n",
        "test_img2=np.expand_dims(test_img2,axis=0)"
      ],
      "metadata": {
        "id": "z84Fj9l3iAO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the classes with the respective name\n",
        "res={0: \"Covid\",\n",
        "     1: \"Normal\"}"
      ],
      "metadata": {
        "id": "SE3JWFdcFjdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(res[round(model.predict(test_img1)[0][0])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55bLx_KYE5pX",
        "outputId": "7fd7eb20-58e3-41ad-bafd-19ed6dac6632"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Covid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(res[round(model.predict(test_img2)[0][0])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JTjceApGXO1",
        "outputId": "30a79d8e-3b8a-4b62-c3d0-07ee69e350d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Normal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After running the model through all 5 epochs we had set, the accuracy comes around 90.32% and the loss is around 16.17 and when the model is compared with the testing data the accuracy comes around 93.48% and the loss comes around 16.85%. We had further tried to take two randon images from the dataset and fed the model for prediction and the model has rightfully predicted the outcome."
      ],
      "metadata": {
        "id": "W0Kx70XmPBfu"
      }
    }
  ]
}